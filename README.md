# **Patrick**

## **Inspiration**

### **Context Is All You Need**

LLMs are kind of dumb. They excel at predicting the next token, but if you ask them about anything outside of their training set, you're SOL. Recently, this problem has been tackled via function calling, but setting these tools up has proved to be quite the ordeal. Thus, Patrick started with a simple goal: build an agentic, modular, and context-aware office assistant with access to all of your tools and files!

That sentence is describing a system‚ÄîPatrick‚Äîthat acts as a kind of bridge between LLMs (like GPT) and productivity tools (like Google Docs, Excel, Notion, Slack, etc.). Let's break it down:

üîß **"Patrick leverages the Model Context Protocol"**  
Model Context Protocol (MCP) is likely a standard or framework that helps large language models safely and efficiently communicate with external tools and data.  
Think of it as a translator or middle layer that lets the AI understand what's happening in another app (like your calendar or spreadsheet) and respond in a relevant way.

üß† **"to enable real-time, secure communication between LLMs and productivity tools"**  
Patrick can:
- Pull data from your tools (e.g., read your emails, notes, to-do lists).
- Send actions back (e.g., schedule a meeting, summarize a doc, autofill a table).
- And it does this securely, without leaking sensitive info or losing context.

‚öôÔ∏è **"It helps users automate tasks, generate content, analyze data, and streamline workflows"**  
Patrick isn't just reading data‚Äîit acts like a smart assistant to:
- Automate tasks (e.g., ‚ÄúCreate weekly report based on this spreadsheet‚Äù).
- Generate content (e.g., ‚ÄúWrite a blog post based on these notes‚Äù).
- Analyze data (e.g., ‚ÄúExplain the trends in this chart‚Äù).
- Streamline workflows (e.g., ‚ÄúSummarize every new task added to Trello daily‚Äù).

üß† **"efficient, context-aware interactions"**  
Patrick remembers the context of what you're doing‚Äîso it's not just blindly answering prompts.  
Example: If you‚Äôre editing a Google Doc and say ‚ÄúTurn this into bullet points,‚Äù Patrick knows ‚Äúthis‚Äù means the current paragraph you're on.

## **How We Built It**

We created Patrick, a smart desktop assistant, by connecting large language models (LLMs) to popular productivity apps like Excel, PowerPoint, and Email using a framework called the Model Context Protocol (MCP).

Here's how our system is structured:

‚úÖ **MCP Client**  
This is the frontend or interface that users interact with.  
It sends user instructions (like "create a presentation" or "read my email") to the backend and displays the response.

‚úÖ **MCP Servers**  
These are modular backend components that give the LLM access to specific applications.  
For example:
- The Gmail MCP server lets the model read/send emails.
- The Excel MCP server allows reading and writing Excel files.
- The PowerPoint MCP server enables creating and editing slides.  
Each server uses a function-calling interface, meaning the model can request actions (like sending an email) by calling specific functions.

‚úÖ **LLM API**  
This is the actual AI model that generates responses based on the user's input.  
We used Google‚Äôs Gemini 2.0 Flash, a powerful LLM with built-in function-calling support.  
MCP is model-agnostic, so you could use any LLM that supports function calls (like OpenAI, Claude, etc.).

## **Challenges We Ran Into**

MCP is very new ‚Äî it was just released in November 2024.  
Because of that, there aren‚Äôt many tutorials, libraries, or best practices.  
We had to choose between two competing approaches to build MCP servers:  
- FastMCP and  
- MCP SDK

This led to compatibility problems and bugs, since the ecosystem isn‚Äôt fully mature yet.  
Despite that, we figured things out through a lot of trial and error.

## **Accomplishments We‚Äôre Proud Of**

We successfully built multiple working MCP servers, each with real functionality:  
‚úÖ **Gmail MCP**: Can read emails, send new ones, and handle attachments.  
‚úÖ **Excel MCP**: Can create spreadsheets, read data, and write updates.  
‚úÖ **PowerPoint MCP**: Can generate and edit slide decks.  
This shows that LLMs can interact with real tools ‚Äî not just answer questions!

## **What We Learned**

MCP doesn't tell the AI what to do ‚Äî it simply gives it a list of tools (functions).  
The LLM must figure out which tool to use, when, and how ‚Äî just like a human assistant.

We tested several LLMs:
- Qwen2.5:7b
- Llama 3.2
- Gemini 2.0 Flash (performed the best)

This taught us a lot about how different models reason about tasks and make decisions.

## **What‚Äôs Next for Patrick**

- Add support for more tools by building new MCP servers.
- Improve security, especially for sensitive actions like sending emails.
- Package the entire system into one executable file, so it‚Äôs easy to install and run.

## **Built With**

- **ElectronJS**: Used to create a clean, modern desktop app that runs on Windows, macOS, and Linux.
- **Model Context Protocol (MCP)**: The framework we used to connect the AI model to external tools.
- **Google Gemini 2.0 Flash**: The AI model that powers Patrick‚Äôs natural language abilities.
- **Node.js, React, and Python**: Core programming tools and frameworks used for building the client and server logic.
